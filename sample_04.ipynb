{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58d3bffb-106e-45e6-8cfd-d51f4d7e39fa",
   "metadata": {},
   "source": [
    "# 🔰PyTorchでニューラルネットワーク基礎 #04 【画像分類・畳み込み層】\n",
    "\n",
    "* Qiitaの記事と連動しています\n",
    "* 利用データ：aiueo.npz\n",
    "* [独立行政法人産業技術総合研究所のETL文字データベース](http://etlcdb.db.aist.go.jp/)を利用させていただきました。「あ・い・う・え・お」の５種類の画像を抽出しMNISTと対応させるべく28x28サイズに縮小したものを利用しています"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb39fa1-0d18-47cd-87e2-036890ee0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf1f2a9-954e-47c9-aca3-4c1323ef418a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device Name: cuda:0\n"
     ]
    }
   ],
   "source": [
    "#デバイスの選択\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using Device Name:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bf85415-7ee5-4a45-bbd9-8bfec37ee035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 精度を計算する関数\n",
    "def accuracy(y, t):\n",
    "    _, argmax_list = torch.max(y, dim=1)\n",
    "    accuracy = sum(argmax_list == t).item()/len(t)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ed4525-2e50-4029-8007-2ccbcde5810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"./aiueo.npz\")\n",
    "x = data[\"x\"]\n",
    "t = data[\"t\"]\n",
    "\n",
    "# torchテンソルに変換\n",
    "x = torch.FloatTensor(x).to(device)\n",
    "t = torch.LongTensor(t).to(device)\n",
    "\n",
    "x, x_test, t, t_test = train_test_split(x,t, test_size=0.1, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ffae40a-33af-49a8-9b05-a53df5ff8c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([712, 1, 28, 28]), torch.Size([80, 1, 28, 28]), torch.Size([712]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, x_test.shape, t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d98124-6149-470a-8c15-d0b3bd7e3bf9",
   "metadata": {},
   "source": [
    "## 確認ポイント\n",
    "1. カーネルサイズと出力後の形状\n",
    "2. out_channelsの効果\n",
    "3. flatten\n",
    "4. Linearのin_featuresの計算方法\n",
    "5. 活性化関数の引数\n",
    "   * nn.LeakyReLU()の場合は、\\_\\_init__ 内でオプションを指定\n",
    "   * F.leaky_relu()の場合は、forward()で使うときに、 l_relu(h, negative_slope=0.01)と使用時にオプションを記入\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b00396d6-b37e-4c0e-a07d-9585057ed607",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### モデル定義\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=5 ,kernel_size=5)\n",
    "        self.act1 = nn.LeakyReLU(negative_slope=0.01)  # Leaky ReLU導入\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 =  nn.Linear(in_features=5*24*24, out_features=100)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=100, out_features=5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = self.cnn1(x)\n",
    "        h2 = self.act1(h1)\n",
    "        h = self.flat(h2)\n",
    "        h = self.act2(self.fc1(h))\n",
    "        y = self.fc2(h)\n",
    "        return y, h1, h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37555b82-d1de-4973-b749-699c137454e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (cnn1): Conv2d(1, 5, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (act1): LeakyReLU(negative_slope=0.01)\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=2880, out_features=100, bias=True)\n",
       "  (act2): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d19406-32fd-4a26-80d7-1e32408b6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()   \n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce232552-ea0d-4243-a0d1-90fcaa4da8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9: loss: 0.9390642046928406, acc: 0.8567415730337079\n",
      "19: loss: 0.4787551760673523, acc: 0.8974719101123596\n",
      "29: loss: 0.336257666349411, acc: 0.9297752808988764\n",
      "39: loss: 0.24548858404159546, acc: 0.9564606741573034\n",
      "49: loss: 0.18027959764003754, acc: 0.9676966292134831\n",
      "59: loss: 0.13152575492858887, acc: 0.973314606741573\n",
      "69: loss: 0.09494158625602722, acc: 0.9817415730337079\n",
      "79: loss: 0.06776448339223862, acc: 0.9873595505617978\n",
      "89: loss: 0.04831302911043167, acc: 0.9901685393258427\n",
      "99: loss: 0.03475889563560486, acc: 0.9957865168539326\n",
      "109: loss: 0.025496196001768112, acc: 0.9985955056179775\n",
      "119: loss: 0.01916482113301754, acc: 1.0\n",
      "129: loss: 0.0148230642080307, acc: 1.0\n",
      "139: loss: 0.011767580173909664, acc: 1.0\n",
      "149: loss: 0.009557913988828659, acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 機械学習\n",
    "LOOP = 150\n",
    "for epoch in range(LOOP):\n",
    "    optimizer.zero_grad()\n",
    "    y,h1,h2 = model(x)\n",
    "    loss = criterion(y, t)\n",
    "    acc  = accuracy(y,t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1)%10 == 0:\n",
    "        print(f\"{epoch}: loss: {loss.item()}, acc: {acc}\")  # バッチ全体での損失や精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87b34f9f-84d1-4453-9f86-75e9f270deb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精度:0.95\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_test,_,_ = model(x_test)\n",
    "test_acc = accuracy(y_test, t_test)\n",
    "print(f\"精度:{test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d3634-9c1d-41f8-b1f1-8be86843d990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
