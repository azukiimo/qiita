{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”°PyTorchã§ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸºç¤ #13 ã€éŸ³æ¥½åˆ†é¡01ãƒ»conv1dã€‘\n",
    "\n",
    "* ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ§‹é€ ã®ç†è§£ã®ãŸã‚ã«ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’å°ã•ãã—ã¦ã€è‰²ã‚“ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã—ãŸã„ï¼\n",
    "\n",
    "## å†…å®¹\n",
    "* Qiitaã®è¨˜äº‹ã¨é€£å‹•ã—ã¦ã„ã¾ã™ã€‚\n",
    "* 1æ¬¡å…ƒç•³ã¿è¾¼ã¿ã¨ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤ã‚’åˆ©ç”¨ã—ã¦éŸ³æ¥½ã‚¸ãƒ£ãƒ³ãƒ«åˆ†é¡ã‚’è¡Œã†ã€‚\n",
    "\n",
    "## æ³¨æ„\n",
    "* [Kaggle: GTZAN Dataset - Music Genre Classification](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification)ã‹ã‚‰GTZANãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "* **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆtrain_data.npzã‚’ä½œæˆã—ãªã„ã¨å‹•ä½œã—ãªã„ã®ã§æ³¨æ„ã—ã¦ãã ã•ã„**\n",
    "\n",
    "\n",
    "\n",
    "## ç›®çš„\n",
    "1. nn.Sequential()ã‚’ä½¿ã£ãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è¨˜è¿°æ–¹æ³•\n",
    "2. batchnorm1dã®æœ‰ç„¡\n",
    "3. adaptiveavgpool1dã®æœ‰ç”¨æ€§\n",
    "\n",
    "\n",
    "## éŸ³å£°åˆ†é¡\n",
    "* 1æ¬¡å…ƒç•³ã¿è¾¼ã¿ã¨batchnorm1dã‚’åˆ©ç”¨ã—ã¦éŸ³å£°åˆ†é¡ã‚’è¡Œã†ã€‚\n",
    "* train_data.npz : å„4ãƒ•ã‚¡ã‚¤ãƒ«ã€5ç§’ã€4åˆ†é¡\n",
    "### ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦\n",
    "* sampling rate 22050\n",
    "* ç³»åˆ—é•·ã®æ™‚é–“ï¼š5ç§’ (22050*5)\n",
    "\n",
    "### ãƒ†ã‚¹ãƒˆç²¾åº¦\n",
    "* é‡è¤‡ãªã—ï¼š90ã€œ100%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 110250), (96,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"./data/train_data.npz\")\n",
    "x = data[\"x\"]\n",
    "t = data[\"t\"]\n",
    "x.shape, t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1æ¬¡å…ƒç•³ã¿è¾¼ã¿å±¤ã¨1æ¬¡å…ƒãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([76, 1, 110250]),\n",
       " torch.Size([20, 1, 110250]),\n",
       " torch.Size([76]),\n",
       " torch.Size([20]),\n",
       " tensor([0, 1, 3, 0, 0, 2, 1, 1, 0, 2, 3, 2, 2, 1, 0, 1, 3, 3, 2, 3],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "X = torch.FloatTensor(x).to(device).view(x.shape[0], 1, x.shape[1])\n",
    "T = torch.LongTensor(t).to(device)\n",
    "\n",
    "x_train, x_test, t_train, t_test = train_test_split(X, T, test_size=0.2, stratify=t, random_state=55)\n",
    "x_train.shape, x_test.shape, t_train.shape, t_test.shape, t_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.features = nn.Sequential(\n",
    "            # ç¬¬1ãƒ–ãƒ­ãƒƒã‚¯\n",
    "            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=500, stride=16),\n",
    "            nn.BatchNorm1d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=2),\n",
    "            \n",
    "            # ç¬¬2ãƒ–ãƒ­ãƒƒã‚¯\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=100, stride=16),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=2),\n",
    "            \n",
    "            # ç¬¬3ãƒ–ãƒ­ãƒƒã‚¯\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=10, stride=4),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AdaptiveAvgPool1d(output_size=8)  # å›ºå®šã‚µã‚¤ã‚ºã®å‡ºåŠ›\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=256 * 8, out_features=512),\n",
    "            nn.BatchNorm1d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(in_features=512, out_features=128),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(in_features=128, out_features=4)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.features(x)\n",
    "        y = self.classifier(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(500,), stride=(16,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv1d(64, 128, kernel_size=(100,), stride=(16,))\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv1d(128, 256, kernel_size=(10,), stride=(4,))\n",
       "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.01)\n",
       "    (11): AdaptiveAvgPool1d(output_size=8)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.3, inplace=False)\n",
       "    (5): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.3, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æå¤±é–¢æ•°ã¨æœ€é©åŒ–é–¢æ•°ã®å®š\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, t):\n",
    "    _,argmax_list = torch.max(y, dim=1)\n",
    "    accuracy = sum(argmax_list == t).item()/len(t)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19: loss: 0.1402178853750229,\tacc:0.9868421052631579\n",
      "39: loss: 0.0501951202750206,\tacc:1.0\n",
      "59: loss: 0.030047224834561348,\tacc:1.0\n",
      "79: loss: 0.0158524289727211,\tacc:1.0\n",
      "99: loss: 0.016375450417399406,\tacc:1.0\n"
     ]
    }
   ],
   "source": [
    "LOOP = 100\n",
    "for epoch in range(LOOP):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  \n",
    "    y = model(x_train)\n",
    "    loss = criterion(y, t_train)\n",
    "    acc  = accuracy(y, t_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1)%20 == 0:\n",
    "        print(f\"{epoch}: loss: {loss.item()},\\tacc:{acc}\")   # æå¤±ã¨ç²¾åº¦ã®è¡¨ç¤º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦æ¤œè¨¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_test = model(x_test)\n",
    "test_acc = accuracy(y_test, t_test)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
