{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔰PyTorchでニューラルネットワーク基礎 #13 【音楽分類01・conv1d】\n",
    "\n",
    "* ネットワークの構造の理解のためにデータサイズを小さくして、色んなパターンを試したい！\n",
    "\n",
    "## 内容\n",
    "* Qiitaの記事と連動しています。\n",
    "* 1次元畳み込みとプーリング層を利用して音楽ジャンル分類を行う。\n",
    "\n",
    "## 注意\n",
    "* [Kaggle: GTZAN Dataset - Music Genre Classification](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification)からGTZANデータセットをダウンロードする必要があります。\n",
    "* **データセットtrain_data.npzを作成しないと動作しないので注意してください**\n",
    "\n",
    "\n",
    "\n",
    "## 目的\n",
    "1. nn.Sequential()を使ったネットワークの記述方法\n",
    "2. batchnorm1dの有無\n",
    "3. adaptiveavgpool1dの有用性\n",
    "\n",
    "\n",
    "## 音声分類\n",
    "* 1次元畳み込みとbatchnorm1dを利用して音声分類を行う。\n",
    "* train_data.npz : 各4ファイル、5秒、4分類\n",
    "### データについて\n",
    "* sampling rate 22050\n",
    "* 系列長の時間：5秒 (22050*5)\n",
    "\n",
    "### テスト精度\n",
    "* 重複なし：90〜100%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 110250), (96,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"./data/train_data.npz\")\n",
    "x = data[\"x\"]\n",
    "t = data[\"t\"]\n",
    "x.shape, t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1次元畳み込み層と1次元プーリング層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([76, 1, 110250]),\n",
       " torch.Size([20, 1, 110250]),\n",
       " torch.Size([76]),\n",
       " torch.Size([20]),\n",
       " tensor([0, 1, 3, 0, 0, 2, 1, 1, 0, 2, 3, 2, 2, 1, 0, 1, 3, 3, 2, 3],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "X = torch.FloatTensor(x).to(device).view(x.shape[0], 1, x.shape[1])\n",
    "T = torch.LongTensor(t).to(device)\n",
    "\n",
    "x_train, x_test, t_train, t_test = train_test_split(X, T, test_size=0.2, stratify=t, random_state=55)\n",
    "x_train.shape, x_test.shape, t_train.shape, t_test.shape, t_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワーク構造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.features = nn.Sequential(\n",
    "            # 第1ブロック\n",
    "            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=500, stride=16),\n",
    "            nn.BatchNorm1d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=2),\n",
    "            \n",
    "            # 第2ブロック\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=100, stride=16),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=2),\n",
    "            \n",
    "            # 第3ブロック\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=10, stride=4),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.AdaptiveAvgPool1d(output_size=8)  # 固定サイズの出力\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=256 * 8, out_features=512),\n",
    "            nn.BatchNorm1d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(in_features=512, out_features=128),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(in_features=128, out_features=4)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.features(x)\n",
    "        y = self.classifier(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(500,), stride=(16,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv1d(64, 128, kernel_size=(100,), stride=(16,))\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv1d(128, 256, kernel_size=(10,), stride=(4,))\n",
       "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.01)\n",
       "    (11): AdaptiveAvgPool1d(output_size=8)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.3, inplace=False)\n",
       "    (5): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.3, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数と最適化関数の定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, t):\n",
    "    _,argmax_list = torch.max(y, dim=1)\n",
    "    accuracy = sum(argmax_list == t).item()/len(t)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19: loss: 0.1402178853750229,\tacc:0.9868421052631579\n",
      "39: loss: 0.0501951202750206,\tacc:1.0\n",
      "59: loss: 0.030047224834561348,\tacc:1.0\n",
      "79: loss: 0.0158524289727211,\tacc:1.0\n",
      "99: loss: 0.016375450417399406,\tacc:1.0\n"
     ]
    }
   ],
   "source": [
    "LOOP = 100\n",
    "for epoch in range(LOOP):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  \n",
    "    y = model(x_train)\n",
    "    loss = criterion(y, t_train)\n",
    "    acc  = accuracy(y, t_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1)%20 == 0:\n",
    "        print(f\"{epoch}: loss: {loss.item()},\\tacc:{acc}\")   # 損失と精度の表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テスト用データを使って検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_test = model(x_test)\n",
    "test_acc = accuracy(y_test, t_test)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
