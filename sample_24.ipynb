{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b658f575",
   "metadata": {},
   "source": [
    "## ğŸ”°PyTorchã§ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åŸºç¤ #24 ã€ãƒãƒ«ãƒãƒ©ãƒ™ãƒ«ãƒ»æ–‡ç« åˆ†é¡ã€‘\n",
    "\n",
    "### å†…å®¹\n",
    "* Qiitaã®è¨˜äº‹ã¨é€£å‹•ã—ã¦ã„ã¾ã™\n",
    "* ç°¡æ˜“ã®BERTã‚¿ã‚¤ãƒ—ã§ãƒãƒ«ãƒãƒ©ãƒ™ãƒ«åˆ†é¡ã€Transformer Encoderã‚’åˆ©ç”¨ã—ãŸãƒãƒ«ãƒãƒ©ãƒ™ãƒ«åˆ†é¡ã¨ãªã‚Šã¾ã™\n",
    "* data/MultiLabelDataSample.json \n",
    "\n",
    "\n",
    "### ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦\n",
    "[chABSA-dataset](https://github.com/chakki-works/chABSA-dataset)ã‚’åŠ å·¥ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚\n",
    "* ãƒ©ãƒ™ãƒ«æ•°ï¼šï¼“ï¼ˆå¦å®šçš„ã€ä¸­ç«‹çš„ã€è‚¯å®šçš„ï¼‰ã‚’ãƒãƒ«ãƒãƒ©ãƒ™ãƒ«ã§æ‰±ã†\n",
    "* ãƒ‡ãƒ¼ã‚¿æ•°ï¼š3300\n",
    "* å˜èªæ•°ï¼š6950\n",
    "* ç³»åˆ—é•·ï¼ˆæ–‡ç« ã®é•·ã•ï¼‰ï¼š58\n",
    "\n",
    "**ã„ã‚ã„ã‚è©¦ã—ãŸçµæœã®ä¸€ã¤**\n",
    "* Exact Match: 0.7782\n",
    "* Hamming: 0.9079\n",
    "* Macro F1: 0.7270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f40f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1c69e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆ©ç”¨ãƒ‡ãƒã‚¤ã‚¹: cuda\n"
     ]
    }
   ],
   "source": [
    "#ãƒ‡ãƒã‚¤ã‚¹ã®é¸æŠ\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"åˆ©ç”¨ãƒ‡ãƒã‚¤ã‚¹:\", device)\n",
    "\n",
    "\n",
    "def label_prediction(y, threshold=0.5):\n",
    "    probs = torch.sigmoid(y)\n",
    "    predictions = (probs >= threshold).float()\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# ç²¾åº¦ã®è¨ˆç®— (Exact Match)\n",
    "def accuracy(y,t, threshold=0.5):\n",
    "    prediction = label_prediction(y, threshold=threshold)\n",
    "    num_correct = (prediction == t).all(-1).sum().item()\n",
    "    accuracy = num_correct/t.size(0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2877defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "with open(\"./data/MultiLabelDataSample.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8309962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2.2195, 23.6269,  1.4070], device='cuda:0'),\n",
       " torch.Size([2475, 58]),\n",
       " torch.Size([825, 58]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ãƒªã‚¹ãƒˆã«å¤‰æ›ã—ã¦ã‹ã‚‰tensorã«\n",
    "# x: IDãƒ™ã‚¯ãƒˆãƒ«\n",
    "# t: ãƒ©ãƒ™ãƒ«ã ã‘ã©ã€BCEæå¤±ã‚’ä½¿ã†ã®ã§ã€Floatã«Floatã«ã—ã¦ãŠã\n",
    "x = torch.LongTensor([item[\"ids\"] for item in data])\n",
    "t = torch.FloatTensor([item[\"labels\"] for item in data])\n",
    "\n",
    "num_positives = t.sum(dim=0)\n",
    "num_negatives = len(t) - num_positives\n",
    "# negative/positiveã®æ¯”ç‡ã‚’pos_weightã«\n",
    "pos_weight = torch.FloatTensor(num_negatives / num_positives)\n",
    "\n",
    "x, x_test, t, t_test = train_test_split(x,t, stratify=t,  random_state=55)\n",
    "\n",
    "x = x.to(device)\n",
    "t = t.to(device)\n",
    "x_test = x_test.to(device)\n",
    "t_test = t_test.to(device)\n",
    "pos_weight = pos_weight.to(device)\n",
    "pos_weight, x.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25817adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆæœŸè¨­å®šï¼ˆä»Šå›ã‹ã‚‰æ•°å€¤ã‚’å¤–å´ã«å‡ºã—ã¦ã¿ã¾ã—ãŸï¼‰\n",
    "WORDS = 6950    # å˜èªæ•° len(word2id)\n",
    "SEQ_LEN = 58    # x.shape[1]  # å…¥åŠ›ã™ã‚‹IDãƒ™ã‚¯ãƒˆãƒ«ã®é•·ã•\n",
    "D_MODEL = 64    # åˆ†æ•£è¡¨ç¾ã®æ¬¡å…ƒ\n",
    "N_HEAD = 8      # ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã®ãƒ˜ãƒƒãƒ‰æ•°\n",
    "DIM_FEEDFORWARD = 256 # TransformerEncoderå±¤ã®ä¸­é–“å±¤ã®ç‰¹å¾´é‡ã®æ¬¡å…ƒ\n",
    "CLASSES = 3     # t.shape[1] ãƒ©ãƒ™ãƒ«ã®æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "957f07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pad_token_id: int=3,  # <pad> idã®æŒ‡å®šï¼šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤0ã¨ã‚ãˆã¦å¤‰æ›´ã—ã¦ã„ã‚‹ã‚ˆ\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pad_token_id = pad_token_id\n",
    "       \n",
    "        # (1) ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿\n",
    "        self.token_embedding = nn.Embedding(num_embeddings=WORDS, embedding_dim=D_MODEL,padding_idx=self.pad_token_id)\n",
    "        \n",
    "        # (2) å­¦ç¿’å¯èƒ½ãªä½ç½®åŸ‹ã‚è¾¼ã¿ï¼ˆ0ã€œmax_len-1ï¼‰\n",
    "        self.pos_embedding = nn.Embedding(num_embeddings=SEQ_LEN, embedding_dim=D_MODEL)\n",
    "\n",
    "        # (3) Layer Normalization ã¨ Dropout\n",
    "        self.layer_norm = nn.LayerNorm(D_MODEL)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # (4) Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=D_MODEL,\n",
    "            nhead=N_HEAD,\n",
    "            dim_feedforward=DIM_FEEDFORWARD,\n",
    "            dropout=0.1,\n",
    "            batch_first=True,   # [batch, seq, d_model] ã§æ‰±ãˆã‚‹ã‚ˆã†ã«\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer,num_layers=6)\n",
    "        \n",
    "        # (5) æ–‡ãƒ™ã‚¯ãƒˆãƒ« â†’ ã‚¯ãƒ©ã‚¹æ•°\n",
    "        self.classifier = nn.Linear(in_features=D_MODEL, out_features=CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # (6) ãƒã‚¹ã‚¯ã®å¤‰æ› TransformerEncoder ç”¨: PAD ID=3ã§PAD ã®ã¨ã“ã‚ãŒ True ã«ãªã‚‹ mask\n",
    "        src_key_padding_mask = (x == self.pad_token_id)\n",
    "        # (7) åŸ‹ã‚è¾¼ã¿\n",
    "        # ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿\n",
    "        tok_emb = self.token_embedding(x)  # [batch, seq_len=58, d_model=64]            \n",
    "        # ä½ç½®åŸ‹ã‚è¾¼ã¿ï¼ˆbroadcastingã§è‡ªå‹•æ‹¡å¼µï¼‰\n",
    "        pos_emb = self.pos_embedding(torch.arange(SEQ_LEN, device=x.device))  # [seq_len=58, d_model=64]\n",
    "        # ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ + ä½ç½®åŸ‹ã‚è¾¼ã¿                     \n",
    "        x = tok_emb + pos_emb.unsqueeze(0)     # [batch, seq_len=58, d_model=64]\n",
    "        \n",
    "        # (8) Layer Normalization ã¨ Dropout\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # (9) Transformer Encoder\n",
    "        h = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "        \n",
    "        # (10) æ–‡ãƒ™ã‚¯ãƒˆãƒ«ã¸ã® Pooling (PADã‚’é™¤å¤–ã—ãŸå¹³å‡)\n",
    "        mask = (~src_key_padding_mask).unsqueeze(-1).float()  # [batch, seq_len, 1]\n",
    "        pooled = (h * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1)  # [batch, d_model]\n",
    "               \n",
    "        # (11) æ–‡ãƒ™ã‚¯ãƒˆãƒ«ã¸ã® Pooling  <BOS>ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆå…ˆé ­ï¼‰ã«æƒ…å ±ã‚’é›†ç´„\n",
    "        #pooled = h[:, 0, :]  # [batch, d_model]\n",
    "        \n",
    "        # (12) åˆ†é¡\n",
    "        y = self.classifier(pooled)  # [batch, num_labels=3]    \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e98da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (token_embedding): Embedding(6950, 64, padding_idx=3)\n",
       "  (pos_embedding): Embedding(58, 64)\n",
       "  (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8292b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82744ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30:\tloss:0.715\tacc:0.415\n",
      "60:\tloss:0.548\tacc:0.536\n",
      "90:\tloss:0.410\tacc:0.657\n",
      "120:\tloss:0.321\tacc:0.750\n",
      "150:\tloss:0.246\tacc:0.789\n",
      "180:\tloss:0.225\tacc:0.840\n",
      "210:\tloss:0.173\tacc:0.861\n",
      "240:\tloss:0.129\tacc:0.908\n",
      "270:\tloss:0.106\tacc:0.922\n",
      "300:\tloss:0.097\tacc:0.933\n"
     ]
    }
   ],
   "source": [
    "LOOP = 300\n",
    "\n",
    "for epoch in range(LOOP):\n",
    "    optimizer.zero_grad()\n",
    "    y = model(x)\n",
    "    loss = criterion(y, t)\n",
    "    acc = accuracy(y,t)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1)%30==0:  \n",
    "        print(f\"{epoch+1}:\\tloss:{loss.item():.3f}\\tacc:{acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f347c099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¤œè¨¼ç²¾åº¦: 0.7782\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_test = model(x_test)\n",
    "acc = accuracy(y_test, t_test)\n",
    "print(f\"æ¤œè¨¼ç²¾åº¦: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce65c4",
   "metadata": {},
   "source": [
    "ã“ã‚Œä»¥é™ã¯ã‚ã‚Šã¨é©å½“ãªæ„Ÿã˜ã§ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad65d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_multilabel(y, t, threshold=0.5, eps=1e-10):\n",
    "    \"\"\"\n",
    "    y: logits, shape [N, L]\n",
    "    t: targets(0/1), shape [N, L]\n",
    "    threshold: float ã‚‚ã—ãã¯ é•·ã•3ã®ãƒªã‚¹ãƒˆ\n",
    "    \"\"\"\n",
    "    probs = torch.sigmoid(y)\n",
    "\n",
    "    # threshold ã‚’ [1, L] ã«æ•´å½¢ã—ã¦ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹\n",
    "    if isinstance(threshold, (float, int)):\n",
    "        thr = torch.full((1, probs.size(1)), float(threshold), device=probs.device, dtype=probs.dtype)\n",
    "    else:\n",
    "        thr = torch.as_tensor(threshold, device=probs.device, dtype=probs.dtype).view(1, -1)\n",
    "        if thr.size(1) != probs.size(1):\n",
    "            raise ValueError(f\"threshold length ({thr.size(1)}) must match num_labels ({probs.size(1)})\")\n",
    "\n",
    "    predictions = (probs >= thr).float()\n",
    "\n",
    "    # Exact Match\n",
    "    exact_acc = (predictions == t).all(dim=-1).float().mean().item()\n",
    "\n",
    "    # Hamming Accuracy\n",
    "    hamming_acc = (predictions == t).float().mean().item()\n",
    "\n",
    "    # label-wise counts\n",
    "    tp = (predictions * t).sum(dim=0)\n",
    "    fp = (predictions * (1 - t)).sum(dim=0)\n",
    "    fn = ((1 - predictions) * t).sum(dim=0)\n",
    "\n",
    "    precision = tp / (tp + fp + eps)\n",
    "    recall = tp / (tp + fn + eps)\n",
    "    f1_per_label = 2 * precision * recall / (precision + recall + eps)\n",
    "\n",
    "    macro_f1 = f1_per_label.mean().item()\n",
    "\n",
    "    return {\n",
    "        \"exact_match\": exact_acc,\n",
    "        \"hamming\": hamming_acc,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"f1_per_label\": f1_per_label.detach().cpu(), \n",
    "        \"precision_per_label\": precision.detach().cpu(),\n",
    "        \"recall_per_label\": recall.detach().cpu(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7e09925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å…¨ä½“ã®æŒ‡æ¨™\n",
      "Exact Match: 0.7782\n",
      "Hamming: 0.9079\n",
      "Macro F1: 0.7270\n",
      "\n",
      "ãƒ©ãƒ™ãƒ«ã”ã¨ã®æŒ‡æ¨™\n",
      "f1 per label: tensor([0.8291, 0.5075, 0.8444])\n",
      "precision per label: tensor([0.8307, 0.5000, 0.8348])\n",
      "recall per label: tensor([0.8275, 0.5152, 0.8542])\n"
     ]
    }
   ],
   "source": [
    "threshold=[0.5, 0.5, 0.5]\n",
    "metrics=evaluate_multilabel(y_test, t_test, threshold=threshold)\n",
    "\n",
    "print(\"å…¨ä½“ã®æŒ‡æ¨™\")\n",
    "print(f\"Exact Match: {metrics['exact_match']:.4f}\")\n",
    "print(f\"Hamming: {metrics['hamming']:.4f}\")\n",
    "print(f\"Macro F1: {metrics['macro_f1']:.4f}\")\n",
    "print(\"\\nãƒ©ãƒ™ãƒ«ã”ã¨ã®æŒ‡æ¨™\")\n",
    "print(f\"f1 per label: {metrics['f1_per_label']}\")\n",
    "print(f\"precision per label: {metrics['precision_per_label']}\")\n",
    "print(f\"recall per label: {metrics['recall_per_label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad0b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
