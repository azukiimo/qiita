{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔰PyTorchでニューラルネットワーク基礎 #14 【音楽分類02・conv1d】\n",
    "\n",
    "## 内容\n",
    "* Qiitaの記事と連動しています\n",
    "* 1次元畳み込みを利用した音楽ジャンル分類\n",
    "\n",
    "## 注意\n",
    "* [Kaggle: GTZAN Dataset - Music Genre Classification](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification)からGTZANデータセットをダウンロードする必要があります。\n",
    "* データセットtrain_data_10.npzを作成しないと動作しないので注意してください\n",
    "\n",
    "### データについて\n",
    "* train_data_10.npz : 各90ファイル、10秒、10分類\n",
    "* sampling rate 22050\n",
    "* 系列長の時間：10秒 (22050*10)\n",
    "\n",
    "### テスト精度\n",
    "* 訓練精度：99%\n",
    "* テスト精度：70〜75%　（結構大きく変わります。色々工夫する余地あり）\n",
    "* 学習ループ100回ですが、もう少しあったほうがいいかも😓\n",
    "\n",
    "### その他\n",
    "* GPU利用時で約20分\n",
    "* Google Colabでも動作します。\n",
    "* モデルの構造を表示させるtorchinfoライブラリを使う場合は事前にインストールが必要です。\n",
    "> pip install torchinfo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset  # ミニバッチの利用\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2691, 220500), (2691,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"./data/train_data_10.npz\")\n",
    "x = data[\"x\"]\n",
    "t = data[\"t\"]\n",
    "x.shape, t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの準備\n",
    "* データをtorch.Tensorに変更\n",
    "* train_test_splitで学習用とテスト用に分割\n",
    "* DataLoaderでミニバッチ学習の準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "X = torch.FloatTensor(x).to(device).view(x.shape[0], 1, x.shape[1])\n",
    "T = torch.LongTensor(t).to(device)\n",
    "\n",
    "x_train, x_test, t_train, t_test = train_test_split(X, T, test_size=0.2, stratify=t, random_state=55)\n",
    "\n",
    "# ミニバッチに区分けする\n",
    "mini_batch_size = 100\n",
    "train_data = TensorDataset(x_train, t_train)\n",
    "train_loader = DataLoader(train_data, batch_size=mini_batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワーク構造\n",
    "* nn.Sequentialを利用して特徴量抽出ブロックと分類ブロックに分けて記述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.features = nn.Sequential(\n",
    "            # 第1ブロック\n",
    "            nn.Conv1d(1, 64, kernel_size=1000, stride=16),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=2),\n",
    "            \n",
    "            # 第2ブロック\n",
    "            nn.Conv1d(64, 128, kernel_size=500, stride=8),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=2),\n",
    "            \n",
    "            # 第3ブロック\n",
    "            nn.Conv1d(128, 256, kernel_size=16, stride=4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(8)  # 固定サイズの出力\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 8, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(1000,), stride=(16,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv1d(64, 128, kernel_size=(500,), stride=(8,))\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv1d(128, 256, kernel_size=(16,), stride=(4,))\n",
       "    (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): AdaptiveAvgPool1d(output_size=8)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.3, inplace=False)\n",
       "    (5): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.3, inplace=False)\n",
       "    (9): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ネットワーク構造の表示\n",
    "* torchinfoライブラリを利用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "DNN                                      [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 256, 8]               --\n",
       "│    └─Conv1d: 2-1                       [1, 64, 13719]            64,064\n",
       "│    └─BatchNorm1d: 2-2                  [1, 64, 13719]            128\n",
       "│    └─ReLU: 2-3                         [1, 64, 13719]            --\n",
       "│    └─MaxPool1d: 2-4                    [1, 64, 6858]             --\n",
       "│    └─Conv1d: 2-5                       [1, 128, 795]             4,096,128\n",
       "│    └─BatchNorm1d: 2-6                  [1, 128, 795]             256\n",
       "│    └─ReLU: 2-7                         [1, 128, 795]             --\n",
       "│    └─MaxPool1d: 2-8                    [1, 128, 396]             --\n",
       "│    └─Conv1d: 2-9                       [1, 256, 96]              524,544\n",
       "│    └─BatchNorm1d: 2-10                 [1, 256, 96]              512\n",
       "│    └─ReLU: 2-11                        [1, 256, 96]              --\n",
       "│    └─AdaptiveAvgPool1d: 2-12           [1, 256, 8]               --\n",
       "├─Sequential: 1-2                        [1, 10]                   --\n",
       "│    └─Flatten: 2-13                     [1, 2048]                 --\n",
       "│    └─Linear: 2-14                      [1, 512]                  1,049,088\n",
       "│    └─BatchNorm1d: 2-15                 [1, 512]                  1,024\n",
       "│    └─ReLU: 2-16                        [1, 512]                  --\n",
       "│    └─Dropout: 2-17                     [1, 512]                  --\n",
       "│    └─Linear: 2-18                      [1, 128]                  65,664\n",
       "│    └─BatchNorm1d: 2-19                 [1, 128]                  256\n",
       "│    └─ReLU: 2-20                        [1, 128]                  --\n",
       "│    └─Dropout: 2-21                     [1, 128]                  --\n",
       "│    └─Linear: 2-22                      [1, 10]                   1,290\n",
       "==========================================================================================\n",
       "Total params: 5,802,954\n",
       "Trainable params: 5,802,954\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.19\n",
       "==========================================================================================\n",
       "Input size (MB): 0.88\n",
       "Forward/backward pass size (MB): 16.08\n",
       "Params size (MB): 23.21\n",
       "Estimated Total Size (MB): 40.17\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, (1,1,220500))  # (バッチサイズ, チャンネル数, 系列長)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数と最適化関数の定義\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, t):\n",
    "    _,argmax_list = torch.max(y, dim=1)\n",
    "    accuracy = sum(argmax_list == t).item()/len(t)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19: loss: 0.4493510623772939,\tacc:0.927142857142857\n",
      "39: loss: 0.1916269390355973,\tacc:0.9638095238095238\n",
      "59: loss: 0.08933362843734878,\tacc:0.9880952380952381\n",
      "79: loss: 0.06818140094124135,\tacc:0.9904761904761905\n",
      "99: loss: 0.032543914614333994,\tacc:0.9952380952380951\n"
     ]
    }
   ],
   "source": [
    "LOOP = 100\n",
    "model.train()\n",
    "for epoch in range(LOOP):\n",
    "    # ミニバッチの処理\n",
    "    total_loss = 0  # 損失の累計を計算\n",
    "    total_acc = 0   # 精度の累計を計算\n",
    "    cnt = 0   # ミニバッチでの繰り返し回数 cntで割れば平均になる\n",
    "    \n",
    "    for x, t in train_loader:      \n",
    "        y = model(x)\n",
    "        loss = criterion(y, t)\n",
    "        acc  = accuracy(y, t)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "        cnt += 1\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1)%20 == 0:\n",
    "        print(f\"{epoch}: loss: {total_loss/cnt},\\tacc:{total_acc/cnt}\")   # 損失と精度の表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テスト用データを使って検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7495361781076066"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_test = model(x_test)\n",
    "test_acc = accuracy(y_test, t_test)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
